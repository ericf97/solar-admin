diff --git a/node_modules/@diffusionstudio/vits-web/dist/types.d.ts b/node_modules/@diffusionstudio/vits-web/dist/types.d.ts
index 86020b0..c80dad4 100644
--- a/node_modules/@diffusionstudio/vits-web/dist/types.d.ts
+++ b/node_modules/@diffusionstudio/vits-web/dist/types.d.ts
@@ -32,5 +32,6 @@ export type Progress = {
 export type InferenceConfg = {
     text: string;
     voiceId: VoiceId;
+    speakerId?: number;
 };
 export type ProgressCallback = (progress: Progress) => void;
diff --git a/node_modules/@diffusionstudio/vits-web/dist/vits-web.js b/node_modules/@diffusionstudio/vits-web/dist/vits-web.js
index e5f8fac..06bddba 100644
--- a/node_modules/@diffusionstudio/vits-web/dist/vits-web.js
+++ b/node_modules/@diffusionstudio/vits-web/dist/vits-web.js
@@ -197,7 +197,7 @@ async function N(e, m) {
       "--espeak_data",
       "/espeak-ng-data"
     ]);
-  }), r = 0, s = i.audio.sample_rate, d = i.inference.noise_scale, g = i.inference.length_scale, U = i.inference.noise_w, k = await f(`${u}/${n}`, m), y = await _.InferenceSession.create(await k.arrayBuffer()), w = {
+  }), r = e.speakerId ?? 0, s = i.audio.sample_rate, d = i.inference.noise_scale, g = i.inference.length_scale, U = i.inference.noise_w, k = await f(`${u}/${n}`, m), y = await _.InferenceSession.create(await k.arrayBuffer()), w = {
     input: new _.Tensor("int64", t, [1, t.length]),
     input_lengths: new _.Tensor("int64", [t.length]),
     scales: new _.Tensor("float32", [d, g, U])
